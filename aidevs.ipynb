{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Whisper\n",
    "usage is quite simple 2 step required:\n",
    "1. open file in read \"r\" & binary \"b\" modes \n",
    "2. feed that file for whisper model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trancription => Cześć! Kiedy ostatnio korzystaliście z sztucznej inteligencji, czy zastanawialiście się nad tym, skąd czerpie ona swoją wiedzę? No pewnie, że tak, inaczej nie byłoby was tutaj na szkoleniu. Ale czy przemyśleliście możliwość dostosowania tej wiedzy do waszych własnych, indywidualnych potrzeb?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from config import Config\n",
    "\n",
    "# open file \n",
    "audio_file = open(\"various/task.mp3\", \"rb\")\n",
    "\n",
    "# call whisper model for that file\n",
    "client = OpenAI(api_key=Config().open_api_key)\n",
    "whisper_response = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\", \n",
    "    file=audio_file\n",
    ")\n",
    "transcript = whisper_response.text\n",
    "print(f\"Trancription => {transcript}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling czyli generowania ustrukturyzowanych danych\n",
    "\n",
    "documentation : https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "- jako dodatkowy parametr zapytania przekazujemy listę funkcji w postaci nazwy, opisu oraz zestaw parametrów\n",
    "- poza tym przesyłamy także listę wiadomości, podobnie jak w klasycznej interakcji z modelem\n",
    "- model w odpowiedzi zwraca nam nazwę funkcji oraz listę wartości jej parametrów\n",
    "- opcjonalnie (ale jest to zwykle potrzebne) wskazujemy, która funkcja ma być wybrana jako domyślna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "[make.com](https://medium.com/dev-bits/a-clear-guide-to-openai-function-calling-with-python-dcbc200c5d70#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjBlNzJkYTFkZjUwMWNhNmY3NTZiZjEwM2ZkN2M3MjAyOTQ3NzI1MDYiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMTQ4NzE3NjUwMjg0OTAzOTczMTkiLCJlbWFpbCI6InJhcGN6eW5za2lAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsIm5iZiI6MTcwMDkyNjU4NywibmFtZSI6IkFydHVyIHJhcGN6ecWEc2tpIiwicGljdHVyZSI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hL0FDZzhvY0pycmRKNzh1R0dyMmlMZ3Z5bVZma0tNU3hET3dDeThSQXlBUHpheDEtbz1zOTYtYyIsImdpdmVuX25hbWUiOiJBcnR1ciIsImZhbWlseV9uYW1lIjoicmFwY3p5xYRza2kiLCJsb2NhbGUiOiJlbiIsImlhdCI6MTcwMDkyNjg4NywiZXhwIjoxNzAwOTMwNDg3LCJqdGkiOiJjOTRkYTY1YWUwZWI4OTQ3M2ZlOWU3NmUwMjQ4MmFjOTJhNGM1YjBlIn0.UfqNI5JJcEwc48p8D189cMchHcoyy_inWyfzDHM0W1znomF_us55lmh7i3uEuYejtRFqmEuPXkqUQ_3OzlDxijJIOwIXbJOdvJWaAtoBWEpRqzmT0ipFfID3-WUUMDdiuwt-iTMHyvkkAyoDGTpJ28XDgY9LQkwUvjpcd_SfGB6JrlJDBJtYCXa3sfbyRyh5NLF69NJmdIHCJg1ztPlSWRGKKQvJL8lmBy3B1u4abm1XRwcH1eCcTtmOE_S6Ed3u2tThz-Tfb0LBMBJJszZk_MAPVNsofjfSQ2e93JlEflBmPhmmuoglNGO3OkeBjVL8iVWs3m4z3zX24raudl9KpQ)\n",
    "first we create schema : \n",
    "PyDantic class to structure a model and convert it to JSON schema to avoid verbosity and errors.\n",
    "\n",
    "goal of this excercise is to return structure answer to question: \n",
    "“Have a title and series of steps for a requested question, and generate a JSON-parsable output”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"properties\": {\n",
      "    \"paragraph\": {\n",
      "      \"title\": \"Paragraph\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"paragraph\"\n",
      "  ],\n",
      "  \"title\": \"SimplePersonModel\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make an actual call to OpenAI and apply an “illusionary” function called “get_answer_for_user_query” by guiding AI to return JSON output\n",
    "function is  `illusionary` because it’s control execution is automatically inferred by OpenAI model using name, description, and output schema but not defined by the developer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"properties\": {\n",
      "    \"paragraph\": {\n",
      "      \"title\": \"Paragraph\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"paragraph\"\n",
      "  ],\n",
      "  \"title\": \"SimplePersonModel\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"paragraph\": \"Pirates were notorious figures who sailed the seas, seeking adventure and plundering ships. These seafaring outlaws were known for their distinctive clothing, eye patches, and peg legs. They would often fly the Jolly Roger, a skull and crossbones flag, to strike fear into the hearts of their victims. Pirates were skilled at navigation and combat, using their swords and pistols to attack unsuspecting vessels. They would seize valuable cargo such as gold, silver, and precious jewels, making them incredibly wealthy. Despite their ruthless reputation, pirates also lived by their own code of honor and had a strong sense of camaraderie. While piracy was eventually suppressed, the legends and lore of pirates continue to captivate our imaginations to this day.\"\\n}', name='provide_answer'), tool_calls=None)\n",
      "{\n",
      "  \"paragraph\": \"Pirates were notorious figures who sailed the seas, seeking adventure and plundering ships. These seafaring outlaws were known for their distinctive clothing, eye patches, and peg legs. They would often fly the Jolly Roger, a skull and crossbones flag, to strike fear into the hearts of their victims. Pirates were skilled at navigation and combat, using their swords and pistols to attack unsuspecting vessels. They would seize valuable cargo such as gold, silver, and precious jewels, making them incredibly wealthy. Despite their ruthless reputation, pirates also lived by their own code of honor and had a strong sense of camaraderie. While piracy was eventually suppressed, the legends and lore of pirates continue to captivate our imaginations to this day.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class SimplePersonModel(BaseModel):\n",
    "    paragraph: str\n",
    "\n",
    "simple_schema = SimplePersonModel.model_json_schema()\n",
    "#print(json.dumps(simple_schema, indent=2))\n",
    "\n",
    "client = OpenAI(api_key=Config().open_api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Write short paragraph about pirates\"}\n",
    "    ],\n",
    "    functions=[\n",
    "      {\n",
    "          \"name\" : \"provide_answer\",\n",
    "          \"description\" : \"Get user answer\",\n",
    "          \"parameters\" : SimplePersonModel.model_json_schema()\n",
    "      }\n",
    "    ],\n",
    "    function_call={\"name\": \"provide_answer\"}\n",
    ")\n",
    "\n",
    "#respone for list \n",
    "print(response.choices[0].message)\n",
    "output = json.loads(response.choices[0].message.function_call.arguments)\n",
    "print(json.dumps(output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## this is more complex example with list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"properties\": {\n",
      "    \"title\": {\n",
      "      \"title\": \"Title\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"steps\": {\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      },\n",
      "      \"title\": \"Steps\",\n",
      "      \"type\": \"array\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"title\",\n",
      "    \"steps\"\n",
      "  ],\n",
      "  \"title\": \"StepByStepAIResponse\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "{\n",
      "  \"title\": \"Receipt for Hilarious and Triggering Joke\",\n",
      "  \"steps\": [\n",
      "    \"Step 1: Enter the setup of the joke\",\n",
      "    \"Step 2: Enter the punchline of the joke\",\n",
      "    \"Step 3: Enter the trigger warning for the joke (if applicable)\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class StepByStepAIResponse(BaseModel):\n",
    "    title: str\n",
    "    steps: List[str]\n",
    "\n",
    "list_schema = StepByStepAIResponse.model_json_schema() \n",
    "\n",
    "# print(json.dumps(list_schema, indent=2))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"Act as senior joke specialis\"},\n",
    "      {\"role\": \"user\", \"content\": \"Give receipt for most hilarious and triggering joke ever\"}\n",
    "    ],\n",
    "    functions=[\n",
    "        {\n",
    "          \"name\": \"get_answer_for_user_query\",\n",
    "          \"description\": \"Get user answer in series of steps\",\n",
    "          \"parameters\": list_schema \n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_answer_for_user_query\"}\n",
    ")\n",
    "\n",
    "output = json.loads(response.choices[0].message.function_call.arguments)\n",
    "print(json.dumps(output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasification example from aidevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"command\": true,\n",
      "  \"type\": \"todo\",\n",
      "  \"tags\": [\n",
      "    \"report\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import pydantic \n",
    "import json\n",
    "import enum\n",
    "\n",
    "class TypeEnum(enum.Enum):\n",
    "    MEMO = \"memory\"\n",
    "    NOTE = \"notes\"\n",
    "    LINK = \"links\"\n",
    "    TODO = \"todo\"\n",
    "  \n",
    "\n",
    "class ClasificationModel(BaseModel):\n",
    "    command: bool \n",
    "    type: TypeEnum = pydantic.Field(...)\n",
    "    tags : List[str]\n",
    "\n",
    "list_schema = ClasificationModel.model_json_schema() \n",
    "\n",
    "# print(json.dumps(list_schema, indent=2))\n",
    "\n",
    "\n",
    "def call_ai(): \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": \"write report for monday \"}\n",
    "        ],\n",
    "        functions=[\n",
    "            {\n",
    "            \"name\": \"clasify_answer\",\n",
    "            \"description\": \"Describe users query with semantic tags and classify with type\",\n",
    "            \"parameters\": list_schema \n",
    "            }\n",
    "        ],\n",
    "        function_call={\"name\": \"clasify_answer\"}\n",
    "    )\n",
    "\n",
    "    output = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(json.dumps(output, indent=2))\n",
    "\n",
    "call_ai()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
