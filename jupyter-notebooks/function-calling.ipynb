{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling czyli generowania ustrukturyzowanych danych\n",
    "\n",
    "documentation : https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "- jako dodatkowy parametr zapytania przekazujemy listę funkcji w postaci nazwy, opisu oraz zestaw parametrów\n",
    "- poza tym przesyłamy także listę wiadomości, podobnie jak w klasycznej interakcji z modelem\n",
    "- model w odpowiedzi zwraca nam nazwę funkcji oraz listę wartości jej parametrów\n",
    "- opcjonalnie (ale jest to zwykle potrzebne) wskazujemy, która funkcja ma być wybrana jako domyślna\n",
    "\n",
    "\n",
    "make an actual call to OpenAI and apply an “illusionary” function called “get_answer_for_user_query” by guiding AI to return JSON output\n",
    "function is  `illusionary` because it’s control execution is automatically inferred by OpenAI model using name, description, and output schema but not defined by the developer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "[make.com](https://medium.com/dev-bits/a-clear-guide-to-openai-function-calling-with-python-dcbc200c5d70#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjBlNzJkYTFkZjUwMWNhNmY3NTZiZjEwM2ZkN2M3MjAyOTQ3NzI1MDYiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMTQ4NzE3NjUwMjg0OTAzOTczMTkiLCJlbWFpbCI6InJhcGN6eW5za2lAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsIm5iZiI6MTcwMDkyNjU4NywibmFtZSI6IkFydHVyIHJhcGN6ecWEc2tpIiwicGljdHVyZSI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hL0FDZzhvY0pycmRKNzh1R0dyMmlMZ3Z5bVZma0tNU3hET3dDeThSQXlBUHpheDEtbz1zOTYtYyIsImdpdmVuX25hbWUiOiJBcnR1ciIsImZhbWlseV9uYW1lIjoicmFwY3p5xYRza2kiLCJsb2NhbGUiOiJlbiIsImlhdCI6MTcwMDkyNjg4NywiZXhwIjoxNzAwOTMwNDg3LCJqdGkiOiJjOTRkYTY1YWUwZWI4OTQ3M2ZlOWU3NmUwMjQ4MmFjOTJhNGM1YjBlIn0.UfqNI5JJcEwc48p8D189cMchHcoyy_inWyfzDHM0W1znomF_us55lmh7i3uEuYejtRFqmEuPXkqUQ_3OzlDxijJIOwIXbJOdvJWaAtoBWEpRqzmT0ipFfID3-WUUMDdiuwt-iTMHyvkkAyoDGTpJ28XDgY9LQkwUvjpcd_SfGB6JrlJDBJtYCXa3sfbyRyh5NLF69NJmdIHCJg1ztPlSWRGKKQvJL8lmBy3B1u4abm1XRwcH1eCcTtmOE_S6Ed3u2tThz-Tfb0LBMBJJszZk_MAPVNsofjfSQ2e93JlEflBmPhmmuoglNGO3OkeBjVL8iVWs3m4z3zX24raudl9KpQ)\n",
    "first we create schema : \n",
    "PyDantic class to structure a model and convert it to JSON schema to avoid verbosity and errors.\n",
    "\n",
    "goal of this excercise is to return structure answer to question: \n",
    "“Have a title and series of steps for a requested question, and generate a JSON-parsable output”.\n",
    "\n",
    "\n",
    "\n",
    "#### Firt load env variables to get open ai key: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "from os import environ\n",
    "env_file = './.env'\n",
    "dotenv.load_dotenv(env_file, override=True)\n",
    "print('MY_VAR = ', environ.get('MY_VAR'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is most basic example of function calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimplePersonModel(BaseModel):\n",
    "    paragraph: str\n",
    "\n",
    "simple_schema = SimplePersonModel.model_json_schema()\n",
    "#print(json.dumps(simple_schema, indent=2))\n",
    "\n",
    "client = OpenAI(api_key=environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Write short paragraph about pirates\"}\n",
    "    ],\n",
    "    functions=[\n",
    "      {\n",
    "          \"name\" : \"provide_answer\",\n",
    "          \"description\" : \"Get user answer\",\n",
    "          \"parameters\" : SimplePersonModel.model_json_schema()\n",
    "      }\n",
    "    ],\n",
    "    function_call={\"name\": \"provide_answer\"}\n",
    ")\n",
    "\n",
    "#respone for list \n",
    "print(response.choices[0].message)\n",
    "output = json.loads(response.choices[0].message.function_call.arguments)\n",
    "print(json.dumps(output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is more complex example with list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimplePersonModel(BaseModel):\n",
    "    paragraph: str\n",
    "\n",
    "simple_schema = SimplePersonModel.model_json_schema()\n",
    "#print(json.dumps(simple_schema, indent=2))\n",
    "\n",
    "client = OpenAI(api_key=environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"Write short paragraph about pirates\"}\n",
    "    ],\n",
    "    functions=[\n",
    "      {\n",
    "          \"name\" : \"provide_answer\",\n",
    "          \"description\" : \"Get user answer\",\n",
    "          \"parameters\" : SimplePersonModel.model_json_schema()\n",
    "      }\n",
    "    ],\n",
    "    function_call={\"name\": \"provide_answer\"}\n",
    ")\n",
    "\n",
    "#respone for list \n",
    "print(response.choices[0].message)\n",
    "output = json.loads(response.choices[0].message.function_call.arguments)\n",
    "print(json.dumps(output, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is example how clasification can be done with function calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pydantic \n",
    "import json\n",
    "import enum\n",
    "\n",
    "class TypeEnum(enum.Enum):\n",
    "    MEMO = \"memory\"\n",
    "    NOTE = \"notes\"\n",
    "    LINK = \"links\"\n",
    "    TODO = \"todo\"\n",
    "  \n",
    "\n",
    "class ClasificationModel(BaseModel):\n",
    "    command: bool \n",
    "    type: TypeEnum = pydantic.Field(...)\n",
    "    tags : List[str]\n",
    "\n",
    "list_schema = ClasificationModel.model_json_schema() \n",
    "\n",
    "# print(json.dumps(list_schema, indent=2))\n",
    "\n",
    "\n",
    "def call_ai(): \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": \"write report for monday \"}\n",
    "        ],\n",
    "        functions=[\n",
    "            {\n",
    "            \"name\": \"clasify_answer\",\n",
    "            \"description\": \"Describe users query with semantic tags and classify with type\",\n",
    "            \"parameters\": list_schema \n",
    "            }\n",
    "        ],\n",
    "        function_call={\"name\": \"clasify_answer\"}\n",
    "    )\n",
    "\n",
    "    output = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    print(json.dumps(output, indent=2))\n",
    "\n",
    "call_ai()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is more complex example where we provide many functions and ai chooses most suiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected function => subtract\n",
      "Output from ai => {\n",
      "  \"first\": 2,\n",
      "  \"second\": 1\n",
      "})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for &: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb Cell 12\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         result \u001b[39m=\u001b[39m tools[function_name](first_number, second_number)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresult is \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m call_ai()\n",
      "\u001b[1;32m/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb Cell 12\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Example how to use output\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m tools \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39madd\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m a, b: a \u001b[39m+\u001b[39m b,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m'\u001b[39m\u001b[39msubtract\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m a, b: a \u001b[39m-\u001b[39m b,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m }\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39mif\u001b[39;00m first_number \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;49;00m \u001b[39m&\u001b[39;49m second_number \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m&\u001b[39m function_name \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m: \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     result \u001b[39m=\u001b[39m tools[function_name](first_number, second_number)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mrr/workspaces/personal/aidevs/jupyter-notebooks/function-calling.ipynb#X14sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresult is \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "\n",
    "class AddSchema(BaseModel):\n",
    "    first: int\n",
    "    second: int \n",
    "\n",
    "class SubtractSchema(BaseModel):\n",
    "    first: int\n",
    "    second: int \n",
    "\n",
    "add_schema = AddSchema.model_json_schema() \n",
    "subtract_schema = SubtractSchema.model_json_schema() \n",
    "\n",
    "\n",
    "# print(json.dumps(list_schema, indent=2))\n",
    "\n",
    "# Create two possible functions to choose from: \n",
    "function_list = [\n",
    "    {\n",
    "        \"name\": \"add\",\n",
    "        \"description\": \"add two numbers\",\n",
    "        \"parameters\": add_schema ,\n",
    "            \"required\": [\n",
    "                \"first\", \"second\"\n",
    "            ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"subtract\",\n",
    "        \"description\": \"substract two numbers\",\n",
    "        \"parameters\": subtract_schema,\n",
    "            \"required\": [\n",
    "                \"first\", \"second\"\n",
    "            ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# call to open ai with those functions 2 and let it deceide which to choose from base on input \n",
    "\n",
    "def call_ai(): \n",
    "    client = OpenAI(api_key=environ.get('OPENAI_API_KEY'))\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": \"2 minus 1\"}\n",
    "        ],\n",
    "        functions=function_list,\n",
    "    )\n",
    "\n",
    "    # fetch data from output \n",
    "    arguments_json_object = json.loads(response.choices[0].message.function_call.arguments)\n",
    "    first_number = arguments_json_object['first']\n",
    "    second_number = arguments_json_object['second']\n",
    "    function_name = response.choices[0].message.function_call.name\n",
    "\n",
    "    print(f\"Selected function => {function_name}\")\n",
    "    print(f\"Output from ai => {json.dumps(arguments_json_object, indent=2)})\")\n",
    "\n",
    "\n",
    "    # Example how to use output\n",
    "    tools = {\n",
    "    'add': lambda a, b: a + b,\n",
    "    'subtract': lambda a, b: a - b,\n",
    "    }\n",
    "\n",
    "    if first_number != None and second_number != None and function_name != None: \n",
    "        result = tools[function_name](first_number, second_number)\n",
    "        print(f\"result is {result}\")\n",
    "\n",
    "\n",
    "call_ai()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
