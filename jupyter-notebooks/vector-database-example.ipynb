{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are points ? \n",
    "- central entity that Qdrant operates with.\n",
    "- is a record consisting of a vector and an optional payload\n",
    "- You can search among the points grouped in one collection based on vector similarit \n",
    "\n",
    "https://qdrant.tech/documentation/concepts/points/#upload-points \n",
    "\n",
    "\n",
    "1st run qdrant database  docker run -p 6333:6333 -v ${pwd}/qdrant:/qdrant/storage qdrant/qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple test → adding points to collection \n",
    "- no validation: will give error if collection exist\n",
    "- works ok: cretes collelction & uploads points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "COLLECTION_NAME = \"test_collection\"\n",
    "\n",
    "q_client = QdrantClient('localhost'  , port = '6333')\n",
    "q_client.create_collection(\n",
    "    collection_name= COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(size=3, distance=models.Distance.COSINE, on_disk=True)\n",
    ")\n",
    "q_client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=models.Batch(\n",
    "        ids=[1],\n",
    "        payloads=[\n",
    "            {\"color\": \"red\"},\n",
    "            {\"color\": \"green\"},\n",
    "            {\"color\": \"blue\"},\n",
    "        ],\n",
    "        vectors=[\n",
    "            [0.9, 0.1, 0.1],\n",
    "            [0.1, 0.9, 0.1], \n",
    "            [0.1, 0.1, 0.9],\n",
    "        ],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similar example but loading vectors from AI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "COLLECTION_NAME = \"embedding_from_ai_collection\"\n",
    "STRING_TO_EMBEDD = \"red is dead\"\n",
    "\n",
    "q_client = QdrantClient('localhost'  , port = '6333')\n",
    "q_client.create_collection(\n",
    "    collection_name= COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE, on_disk=True)\n",
    ")\n",
    "embedding = OpenAIEmbeddings().embed_query(STRING_TO_EMBEDD)\n",
    "print(f\"embedding for word: {STRING_TO_EMBEDD} is type type: {type(embedding)} and values: {embedding}\")\n",
    "q_client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=models.Batch(\n",
    "        ids=[1],\n",
    "        payloads=[\n",
    "            {\"color\": STRING_TO_EMBEDD},\n",
    "        ],\n",
    "        vectors=[embedding]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fully working example with loading from disk & validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "import codecs\n",
    "from langchain.docstore.document import Document\n",
    "from uuid import uuid4\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from qdrant_client.http import models\n",
    "import time\n",
    "\n",
    "\n",
    "COLLECTION_NAME = \"first_collection\"\n",
    "\n",
    "\n",
    "def create_langchain_documents(file_path: str ) -> list[Document]:\n",
    "    \"\"\" \n",
    "    genereate list of langchain documents from file \n",
    "    \n",
    "    \"\"\"    \n",
    "    # step 1 - load documents from file , split them by \\n\\n and store in list\n",
    "\n",
    "    splited_documents = []\n",
    "    with codecs.open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        raw_document = f.read()\n",
    "        splited_documents = raw_document.split(\"\\n\\n\")\n",
    "\n",
    "    ### For debbuging purposes remove all but one element from list\n",
    "    # splited_documents = splited_documents[:1]\n",
    "\n",
    "    # step 2 - convert string documents to langchain documents & add tags to them\n",
    "\n",
    "    langchain_documents = []\n",
    "    for document in splited_documents:\n",
    "        langchain_documents.append(\n",
    "            Document(\n",
    "                page_content=document,\n",
    "                metadata={\n",
    "                    \"source\": COLLECTION_NAME,\n",
    "                    \"content\": document,\n",
    "                    \"uuid\": uuid4(),\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return langchain_documents\n",
    "    # step 3 generate embeddings for documents and create pints\n",
    "\n",
    "\n",
    "def create_points(langchain_documents: list[Document]) -> list[models.PointStruct]:\n",
    "       \n",
    "    \"\"\" \n",
    "    Convert list of langchain documents to list of qdrant points ready to upload to qdrant collection\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    iterator = 0\n",
    "    for l_document in langchain_documents:\n",
    "        embedding = OpenAIEmbeddings().embed_query(l_document.page_content)\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=iterator, payload=l_document.metadata, vector=embedding\n",
    "            )\n",
    "        )\n",
    "        iterator += 1\n",
    "    return points\n",
    "\n",
    "def manage_qadrant_collenction():\n",
    "    # Search for collection\n",
    "\n",
    "    q_client = QdrantClient(\"localhost\", port=\"6333\")\n",
    "    result = q_client.get_collections()\n",
    "    print(f\"searching for collection {COLLECTION_NAME} in {result.collections}\")\n",
    "    indexed = False\n",
    "    for collection in result.collections:\n",
    "        if collection.name == COLLECTION_NAME:\n",
    "            indexed = True\n",
    "            break\n",
    "\n",
    "    # Create collection if not exists\n",
    "\n",
    "    if not indexed:\n",
    "        print(f\"creating collection {COLLECTION_NAME}\")\n",
    "        q_client.create_collection(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=1536, distance=models.Distance.COSINE, on_disk=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # get collection\n",
    "\n",
    "    print(f\"getting created collection {COLLECTION_NAME}\")\n",
    "    first_collection = q_client.get_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "    # if no objects in collection - add some\n",
    "    print(f\"adding documents to collection {COLLECTION_NAME}\")\n",
    "    if first_collection and first_collection.points_count == 0:\n",
    "        documents = create_langchain_documents( \"various/vector-store-example.txt\" )\n",
    "        \n",
    "        start_time = time.time()\n",
    "        points = create_points(documents)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"The function create_points executed in {execution_time} seconds\")\n",
    "                \n",
    "        #upload points to collection\n",
    "        start_time = time.time()     \n",
    "        q_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"The function upsert in {execution_time} seconds\")\n",
    "\n",
    "\n",
    "manage_qadrant_collenction()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved aproach - with batches\n",
    "1. Embed all at once not one-by-one\n",
    "2. Load to quadrant in batches\n",
    "\n",
    "The function executed 5 times faster, \n",
    "mostly because of embedning all at once → but its not attainable for large documents → will have to find max what model can receive and portion text so its maxed\n",
    "\n",
    "The 2nd improvment i.e loading in batches to quardant is faster a bit → but probably on much larger scale it would show much greater proffit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "import codecs\n",
    "from langchain.docstore.document import Document\n",
    "from uuid import uuid4\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from qdrant_client.http import models\n",
    "import time\n",
    "\n",
    "\n",
    "COLLECTION_NAME = \"first_collection\"\n",
    "\n",
    "\n",
    "def create_langchain_documents(file_path: str ) -> list[Document]:\n",
    "    \"\"\" \n",
    "    genereate list of langchain documents from single document\n",
    "    \n",
    "    \"\"\"    \n",
    "\n",
    "    splited_documents = []\n",
    "    with codecs.open(file_path, \"r\", encoding=\"utf8\") as f:\n",
    "        raw_document = f.read()\n",
    "        splited_documents = raw_document.split(\"\\n\\n\")\n",
    "\n",
    "    langchain_documents = []\n",
    "    for document in splited_documents:\n",
    "        langchain_documents.append(\n",
    "            Document(\n",
    "                page_content=document,\n",
    "                metadata={\n",
    "                    \"source\": COLLECTION_NAME,\n",
    "                    \"content\": document,\n",
    "                    \"uuid\": uuid4(),\n",
    "                },\n",
    "            )\n",
    "        )\n",
    "    return langchain_documents\n",
    "\n",
    "def create_batch_points(documents: list[str]) :\n",
    "       \n",
    "    \"\"\" \n",
    "    Convert list of langchain documents to list of qdrant points ready to upload to qdrant collection\n",
    "    \"\"\"\n",
    "    page_content_list = [doc.page_content for doc in documents]\n",
    "    vector_list = OpenAIEmbeddings().embed_documents(page_content_list)\n",
    "    \n",
    "    ids = [str(doc.metadata[\"uuid\"]) for doc in documents]\n",
    "    payloads = [doc.metadata for doc in documents]\n",
    "    \n",
    "    points=models.Batch(\n",
    "        ids = ids, \n",
    "        payloads = payloads,\n",
    "        vectors = vector_list\n",
    "    )\n",
    "    return points\n",
    "\n",
    "\n",
    "def manage_qadrant_collenction():\n",
    "    # Search for collection\n",
    "\n",
    "    q_client = QdrantClient(\"localhost\", port=\"6333\")\n",
    "    result = q_client.get_collections()\n",
    "    print(f\"searching for collection {COLLECTION_NAME} in {result.collections}\")\n",
    "    indexed = False\n",
    "    for collection in result.collections:\n",
    "        if collection.name == COLLECTION_NAME:\n",
    "            indexed = True\n",
    "            break\n",
    "\n",
    "    # Create collection if not exists\n",
    "\n",
    "    if not indexed:\n",
    "        print(f\"creating collection {COLLECTION_NAME}\")\n",
    "        q_client.create_collection(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=1536, distance=models.Distance.COSINE, on_disk=True\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # get collection\n",
    "\n",
    "    print(f\"getting created collection {COLLECTION_NAME}\")\n",
    "    first_collection = q_client.get_collection(collection_name=COLLECTION_NAME)\n",
    "\n",
    "    # if no objects in collection - add some\n",
    "    print(f\"adding documents to collection {COLLECTION_NAME}\")\n",
    "    if first_collection and first_collection.points_count == 0:\n",
    "        documents = create_langchain_documents( \"various/vector-store-example.txt\" )\n",
    "        \n",
    "        # convert to points with vector embeddings\n",
    "        start_time = time.time()\n",
    "        points = create_batch_points(documents)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"The function create_batch_points executed in {execution_time} seconds\")\n",
    "        \n",
    "        # upload batch points to collection\n",
    "        start_time = time.time()\n",
    "        q_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"The function upsert with batches executed in {execution_time} seconds\")\n",
    "\n",
    "\n",
    "manage_qadrant_collenction()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
